{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os, psutil\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from ast import literal_eval\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pickle\n",
    "import awswrangler as wr\n",
    "import boto3\n",
    "import gc\n",
    "import math\n",
    "import pyarrow.parquet as pq\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/IPython/core/interactiveshell.py:3072: DtypeWarning: Columns (12,21) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df_ref = pd.read_csv('cohort_12-04_selected.csv')\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/mnt/main/new-cohort/'\n",
    "\n",
    "\n",
    "States = ['State 1', 'State 2', 'State 3', 'State 4', 'State 5', 'State 6', 'State 7']\n",
    "\n",
    "paths = {x:['', ''] for x in States}\n",
    "\n",
    "for x in States:\n",
    "    paths[x][0] = root + x + 'Dataframe_inst.csv'\n",
    "    paths[x][1] = root + x + 'Dataframe_proc.csv'\n",
    "    \n",
    "paths['State 5'][1] = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get POU outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy matrix of NDC codes and metadata for opioid drugs, as determined by the CDC\n",
    "cdc_opioids = pd.read_csv(\"~/Desktop/Resources/CDC_Opioids.csv\")\n",
    "cdc_opioids.loc[:,\"ABUSE_DETER\"] = 0\n",
    "#Numpy matrix of NDC codes and metadata for opioid drugs with less abuse potential, as determined by the CDC\n",
    "abuse_deter_opioids = pd.read_csv(\"~/Desktop/Resources/abuse_deterent.csv\")\n",
    "abuse_deter_opioids.loc[:,\"ABUSE_DETER\"] = 1\n",
    "opioid_info = pd.concat([abuse_deter_opioids,cdc_opioids])\n",
    "opioid_info = opioid_info[opioid_info['Drug'] != 'Buprenorphine']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/ipykernel_launcher.py:4: UserWarning: DataFrame columns are not unique, some columns will be omitted.\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "product_dict = {opioid_info['NDC_Numeric'].loc[i]: opioid_info['Drug'].loc[i] for i in opioid_info.index}\n",
    "drugs = set(product_dict.values())\n",
    "\n",
    "product_dict_precise = opioid_info[['NDC_Numeric', 'Drug', 'Strength_Per_Unit', 'MME_Conversion_Factor']].set_index('NDC_Numeric').T.to_dict('list')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pou_outcome(surgery_dt, claim_from_dt, denied, product_cd, generic_drug_nm, drug_name,\n",
    "                    drug_list = ['Codeine','Hydrocodone','Hydromorphone','Morphine','Oxycodone','Tramadol'], tolerance = 10):\n",
    "    \n",
    "    res = {}\n",
    "\n",
    "    res['Prolonged_user'] = 0\n",
    "    \n",
    "    \n",
    "    if product_cd != product_cd:\n",
    "        return res\n",
    "    \n",
    "    claim_dates = literal_eval(claim_from_dt)\n",
    "    codes = literal_eval(product_cd.replace('nan', \"'nan'\"))\n",
    "    drug_nm_list = literal_eval(generic_drug_nm.replace('nan', \"'nan'\"))\n",
    "    denied_list = literal_eval(denied)\n",
    "    \n",
    "    try:\n",
    "        drug_nm_2_list = literal_eval(drug_name.replace('nan', \"'nan'\"))\n",
    "    except:\n",
    "        drug_nm_2_list = drug_nm_list\n",
    "        \n",
    "    surg_dt = datetime.strptime(surgery_dt,'%Y-%m-%d')\n",
    "    \n",
    "    \n",
    "    for i,cd in enumerate(codes):\n",
    "        \n",
    "        try:\n",
    "            cd_ = int(float(cd))\n",
    "        except:\n",
    "            cd_ = 0\n",
    "        \n",
    "        claim_dt = datetime.strptime(claim_dates[i],'%Y-%m-%d')\n",
    "        delay = (claim_dt - surg_dt).days\n",
    "        drug_nm = drug_nm_list[i]\n",
    "        drug_nm_2 = drug_nm_2_list[i]\n",
    "        \n",
    "        \n",
    "        if cd_ in product_dict:\n",
    "            \n",
    "            # Find prolonged opioid user\n",
    "            if res['Prolonged_user'] == 0 and delay >= 90 and delay <= 180:\n",
    "                res['Prolonged_user'] = 1\n",
    "                \n",
    "        else:\n",
    "            if res['Prolonged_user'] == 0 and delay >= 90 and delay <= 180:\n",
    "                for x in drug_list:\n",
    "                    if x.lower()[:-2] in drug_nm.lower() or x.lower()[:-2] in drug_nm_2.lower():\n",
    "                        res['Prolonged_user'] = 1\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_surg_date(c, i):\n",
    "    if i != i or i[:2] != \"20\":\n",
    "        return c\n",
    "    else:\n",
    "        return i\n",
    "    \n",
    "def select_rx_date(w, c):\n",
    "    if w != w or len(str(w)) <= 2:\n",
    "        return c\n",
    "    else:\n",
    "        return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pou_outcome = pd.DataFrame()\n",
    "base_columns = ['MA_NUM', 'State', 'CLAIM_FROM_DT', 'ICD9_CD', 'ICD9_DT', 'SURG_DT']\n",
    "columns_to_load = base_columns + ['EGPCD_RF', 'CLAIM_FROM_DT_rx', 'RX_WRITTEN_DT', 'Denied', 'PRODUCT_CD', 'GENERIC_DRUG_NM', 'DRUG_NAME', 'CLAIM_FROM_DT_inst', 'CLAIM_FROM_DT_dx', 'PLACE_OF_SRVC_CD_dx']\n",
    "\n",
    "for STATE in States:\n",
    "    print('Working on {}'.format(STATE))\n",
    "    temp_MA_nums = set(df_ref[df_ref.State == STATE].MA_NUM.values)\n",
    "    \n",
    "    df_1 = pd.read_csv(paths[STATE][0], usecols = columns_to_load)\n",
    "    df_1['SURG_DT'] = df_1[['CLAIM_FROM_DT','SURG_DT']].apply(lambda x: find_surg_date(x[0], x[1]), axis = 1)\n",
    "    df_1['Codes_procedures'] = df_1['ICD9_CD']\n",
    "    \n",
    "    if not paths[STATE][1]:\n",
    "        df_2 = pd.DataFrame([], columns = columns_to_load)\n",
    "    else:\n",
    "        df_2 = pd.read_csv(paths[STATE][1], usecols = columns_to_load + ['ICD9_CD_proc'])\n",
    "        df_2['SURG_DT'] = df_2[['CLAIM_FROM_DT','SURG_DT']].apply(lambda x: find_surg_date(x[0], x[1]), axis = 1)\n",
    "        df_2['Codes_procedures'] = df_2['ICD9_CD_proc']\n",
    "    \n",
    "    print('Loaded csvs')\n",
    "    \n",
    "    pair_set = set([tuple(x) for x in df_1[['MA_NUM', 'CLAIM_FROM_DT']].values.tolist()])\n",
    "    df_2 = df_2[df_2[['MA_NUM', 'CLAIM_FROM_DT']].apply(lambda x: tuple(x) not in pair_set , axis = 1)]\n",
    "\n",
    "    df_1['Source'] = 'Inst'\n",
    "    df_2['Source'] = 'Proc'\n",
    "\n",
    "    df = pd.concat([df_1, df_2], axis = 0)[columns_to_load + ['Source','Codes_procedures']].reset_index()\n",
    "    \n",
    "    if STATE == 'State 4':\n",
    "        df = df[df['SURG_DT'].apply(lambda x: x[:4]) != '2020']\n",
    "    \n",
    "    \n",
    "    print('Concatenation done')\n",
    "    \n",
    "    \n",
    "    del df_1\n",
    "    del df_2\n",
    "    \n",
    "    \n",
    "    if STATE == 'State 5':\n",
    "        df['RX_DATES'] = df['CLAIM_FROM_DT_rx']\n",
    "    else:\n",
    "        df['RX_DATES'] = df[['RX_WRITTEN_DT', 'CLAIM_FROM_DT_rx']].apply(lambda x: select_rx_date(x[0], x[1]), axis = 1)\n",
    "    print('Creating dataframe')\n",
    "    \n",
    "    df = df.sort_values(by='SURG_DT').drop_duplicates(subset = ['MA_NUM'], keep = \"last\")\n",
    "    \n",
    "    df = df[df.MA_NUM.isin(temp_MA_nums)]\n",
    "    \n",
    "    df = df[['MA_NUM','SURG_DT', 'RX_DATES', 'Denied', 'PRODUCT_CD', 'GENERIC_DRUG_NM', 'DRUG_NAME']]\n",
    "    \n",
    "    temp_pou_outcome = df[['SURG_DT', 'RX_DATES', 'Denied', 'PRODUCT_CD', 'GENERIC_DRUG_NM', 'DRUG_NAME']].progress_apply( lambda x: get_pou_outcome(x[0],\n",
    "                                                                     x[1],\n",
    "                                                                     x[2],\n",
    "                                                                     x[3],\n",
    "                                                                     x[4],\n",
    "                                                                     x[5]), \n",
    "                                                                     axis = 1) \n",
    "    \n",
    "    temp_pou_outcome = pd.concat([temp_pou_outcome.apply(pd.Series), df[['MA_NUM']]], axis = 1)\n",
    "    \n",
    "    pou_outcome = pd.concat([pou_outcome, temp_pou_outcome], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "pou_outcome.to_csv('pou_outcome.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('cohort_12-04_selected.csv')\n",
    "pou_outcome = pd.read_csv('pou_outcome.csv')\n",
    "df = df.merge(pou_outcome, on = 'MA_NUM', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = set(df.columns) - {\"MA_NUM\", \"HCPCS_CD\", \"CLAIM_FROM_DT\", \"ICD9_CD\", \"ICD9_DT\", \n",
    "                              \"DISCHARG_DT\", \"POLICY_START_DT\", \"POLICY_END_DT\", \"DOB_DT\",\n",
    "                              \"LNGCD_RF\", \"AIDCT_RF\", \"Source\", 'Start_dt', 'End_dt', 'Overdose_Death', \"Race\", \"Outcome_Abuse_3months\", \"Outcome_Abuse_3months\",\n",
    "                              \"Outcome_Abuse_6months\", \"Outcome_Abuse_12months\", \"Outcome_Overdose_3months\",\n",
    "                              \"Outcome_Overdose_6months\", \"Outcome_Overdose_12months\", \"Outcome_Overdose_12months\",\n",
    "                              \"Outcome_3months\", \"Outcome_12months\", \"Outcome_6months\", \"ZIP\", \"ZCTA5\", \"FIPS\", \"Main_Provider\", 'Continuously_Enrolled_12months'}\n",
    "\n",
    "columns = [x for x in df.columns if x in columns]\n",
    "\n",
    "df = df[columns]\n",
    "\n",
    "columns = [x for x in columns if x!='State']\n",
    "df =df[columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoders = {}\n",
    "\n",
    "for f in ['GENCD_RF', 'Surgery_type']:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[f])\n",
    "    label_encoders[f] = le.classes_\n",
    "    df[f+'_enc'] = le.transform(df[f])\n",
    "    \n",
    "df.drop(columns = ['GENCD_RF', 'Surgery_type', 'SURG_DT'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.rename(columns = {'Prolonged_user': 'Outcome_6months'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results with POU outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummies = pd.get_dummies(df['Surgery_type_enc'], prefix='Surgery')\n",
    "df[dummies.columns] = dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_columns = [x for x in df.columns if (x != 'Surgery_type_enc')]\n",
    "RF_columns = new_columns\n",
    "LR_columns = RF_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(df[new_columns], test_size = 0.1, stratify = df['Outcome_6months'], random_state = 1)\n",
    "\n",
    "X_train, y_train = df_train.drop(columns = ['Outcome_6months']), df_train['Outcome_6months']\n",
    "X_test, y_test = df_test.drop(columns = ['Outcome_6months']), df_test['Outcome_6months']\n",
    "\n",
    "X_train = X_train.fillna(X_train.median())\n",
    "X_test = X_test.fillna(X_test.median())\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(y_test, y_pred, thresh = 0.5):\n",
    "    auc = roc_auc_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred >= thresh)\n",
    "    p = precision_score(y_test, y_pred >= thresh)\n",
    "    r = recall_score(y_test, y_pred >= thresh)\n",
    "    return auc, f1, p, r\n",
    "    \n",
    "def test_split(model, X_test, y_test, random_state = 1, n_splits = 5):\n",
    "    \"\"\"Evaluation process: split the test set in 5 splits, evaluate the model on each split and \n",
    "       return the average/std of each metric\"\"\"\n",
    "    shuffled = np.concatenate([X_test, y_test.values.reshape(-1,1)], axis = 1)\n",
    "    \n",
    "    splits = np.array_split(shuffled, n_splits)\n",
    "    \n",
    "    metrics = np.zeros((n_splits, 4))\n",
    "    \n",
    "    for i,x in enumerate(splits):\n",
    "        \n",
    "        y_pred = model.predict(x[:,:-1])\n",
    "        try:\n",
    "            y_pred_split = model.predict_proba(x[:,:-1])[:,1]\n",
    "        except:\n",
    "            y_pred_split = model.predict_proba(x[:,:-1])\n",
    "        y_test_split = x[:,-1]\n",
    "        metrics[i,:] = get_metrics(y_test_split,y_pred_split, thresh = model.thresh)\n",
    "    \n",
    "    res = pd.DataFrame(np.array([metrics.mean(axis = 0), metrics.std(axis = 0)]).T, columns = ['Mean', 'Std'], index = ['AUC', 'F1', 'Precision', 'Recall'])\n",
    "    return res   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class new_model:\n",
    "    \"\"\" Class used to easily use thresholding for model prediction\"\"\"\n",
    "    def __init__(self, mod, thresh = None):\n",
    "        self.model = mod\n",
    "        if thresh:\n",
    "            self.thresh = thresh    \n",
    "        return\n",
    "    \n",
    "    def predict(self, X_test):\n",
    "        try:\n",
    "            proba_predicted = self.model.predict_proba(X_test)[:,1]\n",
    "        except:\n",
    "            proba_predicted = self.model.predict_proba(X_test)\n",
    "        return proba_predicted >= self.thresh\n",
    "    \n",
    "    def predict_proba(self, X_test):\n",
    "        return self.model.predict_proba(X_test)\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.813840</td>\n",
       "      <td>0.013647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.573821</td>\n",
       "      <td>0.028539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.687318</td>\n",
       "      <td>0.024653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.492953</td>\n",
       "      <td>0.031900</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.813840  0.013647\n",
       "F1         0.573821  0.028539\n",
       "Precision  0.687318  0.024653\n",
       "Recall     0.492953  0.031900"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = LogisticRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "test_split(new_model(lr, 0.36), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.814211</td>\n",
       "      <td>0.013373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.584788</td>\n",
       "      <td>0.027012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.657756</td>\n",
       "      <td>0.024092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.526721</td>\n",
       "      <td>0.030646</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.814211  0.013373\n",
       "F1         0.584788  0.027012\n",
       "Precision  0.657756  0.024092\n",
       "Recall     0.526721  0.030646"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge = LogisticRegression(penalty = 'l2', C = 0.001)\n",
    "ridge.fit(X_train, y_train)\n",
    "test_split(new_model(ridge, 0.32), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.814404</td>\n",
       "      <td>0.013333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.586553</td>\n",
       "      <td>0.025193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.657468</td>\n",
       "      <td>0.021446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.529773</td>\n",
       "      <td>0.029402</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.814404  0.013333\n",
       "F1         0.586553  0.025193\n",
       "Precision  0.657468  0.021446\n",
       "Recall     0.529773  0.029402"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso = LogisticRegression(penalty = 'l1', solver = 'saga', C = 0.05)\n",
    "lasso.fit(X_train, y_train)\n",
    "test_split(new_model(lasso, 0.32), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Elastic net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/sklearn/linear_model/_sag.py:329: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.814917</td>\n",
       "      <td>0.012928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.583875</td>\n",
       "      <td>0.026434</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.670692</td>\n",
       "      <td>0.023875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.517349</td>\n",
       "      <td>0.030015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.814917  0.012928\n",
       "F1         0.583875  0.026434\n",
       "Precision  0.670692  0.023875\n",
       "Recall     0.517349  0.030015"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elnet = LogisticRegression(penalty = 'elasticnet', solver = 'saga', C = 0.01, l1_ratio = 0.5)\n",
    "elnet.fit(X_train, y_train)\n",
    "test_split(new_model(elnet, 0.33), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.809236</td>\n",
       "      <td>0.011932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.583497</td>\n",
       "      <td>0.030448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.660381</td>\n",
       "      <td>0.025703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.523242</td>\n",
       "      <td>0.035854</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.809236  0.011932\n",
       "F1         0.583497  0.030448\n",
       "Precision  0.660381  0.025703\n",
       "Recall     0.523242  0.035854"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators = 300, random_state = 1)\n",
    "rf.fit(X_train, y_train)\n",
    "test_split(new_model(rf, 0.35), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/sklearn.py:1146: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:05:44] WARNING: ../src/learner.cc:1095: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/xgboost/data.py:115: UserWarning: Use subset (sliced data) of np.ndarray is not recommended because it will generate extra copies and increase memory consumption\n",
      "  \"memory consumption\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.819188</td>\n",
       "      <td>0.010050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.588103</td>\n",
       "      <td>0.034049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.684794</td>\n",
       "      <td>0.029314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.516158</td>\n",
       "      <td>0.039994</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.819188  0.010050\n",
       "F1         0.588103  0.034049\n",
       "Precision  0.684794  0.029314\n",
       "Recall     0.516158  0.039994"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import xgboost as xgb\n",
    "\n",
    "xg = xgb.XGBClassifier(random_state = 1, eta=0.05, reg_lambda = 0.5)\n",
    "xg.fit(X_train, y_train)\n",
    "test_split(new_model(xg, 0.35), X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deep NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout,normalization,BatchNormalization,LSTM,GRU\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "2728/2728 [==============================] - 7s 2ms/step - loss: 0.4528 - auc: 0.7290 - val_loss: 0.3955 - val_auc: 0.8114\n",
      "Epoch 2/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3870 - auc: 0.8034 - val_loss: 0.3809 - val_auc: 0.8123\n",
      "Epoch 3/10\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.3794 - auc: 0.8118 - val_loss: 0.3868 - val_auc: 0.8129\n",
      "Epoch 4/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3755 - auc: 0.8157 - val_loss: 0.3835 - val_auc: 0.8136\n",
      "Epoch 5/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3746 - auc: 0.8200 - val_loss: 0.3764 - val_auc: 0.8139\n",
      "Epoch 6/10\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.3654 - auc: 0.8257 - val_loss: 0.3770 - val_auc: 0.8158\n",
      "Epoch 7/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3717 - auc: 0.8224 - val_loss: 0.3771 - val_auc: 0.8126\n",
      "Epoch 8/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3668 - auc: 0.8263 - val_loss: 0.3812 - val_auc: 0.8111\n",
      "Epoch 9/10\n",
      "2728/2728 [==============================] - 6s 2ms/step - loss: 0.3649 - auc: 0.8306 - val_loss: 0.3813 - val_auc: 0.8120\n",
      "Epoch 10/10\n",
      "2728/2728 [==============================] - 5s 2ms/step - loss: 0.3627 - auc: 0.8316 - val_loss: 0.3868 - val_auc: 0.8084\n"
     ]
    }
   ],
   "source": [
    "dnn = Sequential()\n",
    "dnn.add(Dense(128, activation='relu',input_shape=(X_train.shape[1],)))\n",
    "dnn.add(Dropout(0.4))\n",
    "dnn.add(Dense(128, activation='relu',input_shape=(X_train.shape[1],)))\n",
    "dnn.add(Dropout(0.4))\n",
    "dnn.add(Dense(128, activation='relu',input_shape=(X_train.shape[1],)))\n",
    "dnn.add(Dropout(0.4))\n",
    "dnn.add(Dense(32, activation='relu'))\n",
    "dnn.add(Dropout(0.4))\n",
    "dnn.add(Dense(8, activation='relu'))\n",
    "dnn.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "opt = Adam(learning_rate=0.001)\n",
    "dnn.compile(loss='binary_crossentropy',optimizer=opt,metrics=['AUC'])\n",
    "history = dnn.fit(X_train,y_train,epochs=10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n",
      "/home/ubuntu/.local/lib/python3.6/site-packages/tensorflow/python/keras/engine/sequential.py:425: UserWarning: `model.predict_proba()` is deprecated and will be removed after 2021-01-01. Please use `model.predict()` instead.\n",
      "  warnings.warn('`model.predict_proba()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.808575</td>\n",
       "      <td>0.015507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.579094</td>\n",
       "      <td>0.027629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.646955</td>\n",
       "      <td>0.022597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.524788</td>\n",
       "      <td>0.034601</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Mean       Std\n",
       "AUC        0.808575  0.015507\n",
       "F1         0.579094  0.027629\n",
       "Precision  0.646955  0.022597\n",
       "Recall     0.524788  0.034601"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_split(new_model(dnn, 0.31), X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
